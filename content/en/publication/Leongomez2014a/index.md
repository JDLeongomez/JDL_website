+++
title = "Contextual musicality: Vocal modulation and its perception in human social interactions"
date = 2014-07-13T00:00:00

# Authors. Comma separated list, e.g. `["Bob Smith", "David Jones"]`.
authors = ["admin"]

# Publication type.
# Legend:
# 0 = Uncategorized
# 1 = Conference paper
# 2 = Journal article
# 3 = Manuscript
# 4 = Report
# 5 = Book
# 6 = Book section
# 7 = Thesis (v4.2+ required)
# 8 = Patent (v4.2+ required)
publication_types = ["7"]

# Publication name and optional abbreviated version.
publication = "[PhD, University of Stirling]"
publication_short = ""

# Abstract.
abstract = "Music and language are both deeply rooted in our biology, but scientists have given far more attention to the neurological, biological and evolutionary roots of language than those of music. Because of this, and probably partially due to this, the purpose of music, in evolutionary terms, remains a mystery. Our brain, physiology and psychology make us capable of producing and listening to music since early infancy; therefore, our biology and behaviour are carrying some of the clues that need to be revealed to understand what music is “for”. Furthermore, music and language have a deep relationship, particularly in terms of cognitive processing, that can provide clues about the origins of music. Non-verbal behaviours, including voice characteristics during speech, are an important form of communication that enables individual recognition and assessment of the speaker’s physical characteristics (including sex, femininity/masculinity, body size, physical strength, and attractiveness). Vocal parameters, however, can be intentionally varied, for example altering the intensity (loudness), rhythm and pitch during speech. This is classically demonstrated in infant directed speech (IDS), in which adults alter vocal characteristics such as pitch, cadence and intonation contours when speaking to infants. In this thesis, I analyse vocal modulation and its perception in human social interaction, in different social contexts such as courtship and authority ranking relationships. Results show that specific vocal modulations, akin to those of IDS, and perhaps music, play a role in communicating courtship intent. Based on these results, as well the body of current knowledge, I then propose a model for the evolution of musicality, the human capacity to process musical information, in relation to human vocal communication. I suggest that musicality may not be limited to specifically musical contexts, and can have a role in other domains such as language, which would provide further support for a common origin of language and music. This model supports the hypothesis of a stage in human evolution in which individuals communicated using a music-like protolanguage, a hypothesis first suggested by Darwin."

# Summary. An optional shortened abstract.
summary = ""

# Digital Object Identifier (DOI)
doi = "10.13140/RG.2.2.36521.39520"

# Is this a featured publication? (true/false)
featured = false

# Tags (optional).
#   Set `tags = []` for no tags, or use the form `tags = ["A Tag", "Another Tag"]` for one or more tags.
tags = ["Mate choice", "Origins of music", "Musicality", "Psychoacoustics", "Protolanguage", "Voice modulation", "Voice pitch", "f0", "Human voice"]

# Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["deep-learning"]` references
#   `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects = []

# Slides (optional).
#   Associate this publication with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references
#   `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
slides = ""

# Links (optional).
url_pdf = "https://dspace.stir.ac.uk/bitstream/1893/21102/3/Contextual%20Musicality_Juan%20David%20Leongomez.pdf"
url_preprint = ""
url_code = ""
url_dataset = ""
url_project = ""
url_slides = ""
url_video = ""
url_poster = ""
url_source = "http://hdl.handle.net/1893/21102"

# Custom links (optional).
#   Uncomment line below to enable. For multiple links, use the form `[{...}, {...}, {...}]`.
# links = [{name = "Custom Link", url = "http://example.org"}]

# Does this page contain LaTeX math? (true/false)
math = true

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
[image]
  # Caption (optional)
  caption = "Image credit: **Eugenio Valderrama, Juan David Leongómez 2014**"

  # Focal point (optional)
  # Options: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight
  focal_point = "BottomLeft"
+++

<script type='text/javascript' src='https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js'></script>

<html>
  <style>
    section {
        background: white;
        color: white;
        border-radius: 1em;
        padding: 1em;
        left: 50% }
    #inner {
        display: inline-block;
        display: flex;
        align-items: center;
        justify-content: center }
  </style>
  <section>
    <div id="inner">
      <span style="float:left"; class="__dimensions_badge_embed__" data-doi="10.13140/RG.2.2.36521.39520" data-hide-zero-citations="true" data-legend="always">
      </span><script async src="https://badge.dimensions.ai/badge.js" charset="utf-8"></script>
      <div  style="float:right"; data-link-target="_blank" data-badge-details="right" data-badge-type="medium-donut"
      data-doi="10.13140/RG.2.2.36521.39520"   data-condensed="true" data-hide-no-mentions="true" class="altmetric-embed"></div>
    </div>
  </section>
