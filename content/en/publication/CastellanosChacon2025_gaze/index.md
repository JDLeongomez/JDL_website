+++
title = "Effects of stimulus emotional content on gaze pattern: an eye-tracking study"
date = 2025-01-30T00:00:00

# Authors. Comma separated list, e.g. `["Bob Smith", "David Jones"]`.
authors = ["ancc", "admin", "Daniela Arias-Otero", "Valeria Uribe-Jaramillo", "mva"]

# Publication type.
# Legend:
# 0 = Uncategorized
# 1 = Conference paper
# 2 = Journal article
# 3 = Manuscript
# 4 = Report
# 5 = Book
# 6 = Book section
publication_types = ["3"]

# Publication name and optional abbreviated version.
publication = "Submitted for publication"
publication_short = ""

# Abstract.
abstract = "When stimuli with negative, positive, and without emotional content compete for attention, the attentional system prioritizes negative stimuli in early stages of processing, serving as a survival mechanism in response to potential threats. However, the persistence or reversal of this attentional bias towards positive stimuli during later processing stages remains unclear. To address this question, we used eye tracking technology to examine how the simultaneous presentation of stimuli, encompassing negative and positive emotional content alongside emotionally neutral stimuli, while controlling for the presence of humans, neutral (humans in non-emotional activities), and control stimuli (inanimate objects), affects both early and late attentional patterns in observers. These effects were tested in a free-viewing task involving a sample of 122 participants (64 men, 58 women) without affective disorders, data were taken between 2022 and 2023. Our results showed that negative stimuli elicited quicker initial fixation and a higher count of first fixations compared to positive, neutral, and control stimuli. Moreover, negative stimuli led to longer fixation durations and greater overall number of fixations than positive and non-emotional stimuli. Notably, emotional stimuli consistently exhibited a higher attentional preference over non-emotional stimuli, and stimuli featuring human faces, even devoid of emotional context, garnered greater attentional preference than inanimate objects. "

# Summary. An optional shortened abstract.
summary = ""

# Digital Object Identifier (DOI)
doi = ""

# Is this a featured publication? (true/false)
featured = false

# Tags (optional).
#   Set `tags = []` for no tags, or use the form `tags = ["A Tag", "Another Tag"]` for one or more tags.
tags = ["Attentional biases", "Emotional content", "Early attention", "Late attention", "Eye tracking"]

# Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["deep-learning"]` references
#   `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects = []

# Slides (optional).
#   Associate this publication with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references
#   `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
slides = ""

# Links (optional).
url_pdf = ""
url_preprint = ""
url_code = ""
url_dataset = ""
url_project = ""
url_slides = ""
url_video = ""
url_poster = ""
url_source = ""

# Custom links (optional).
# For multiple links, use the form `[{...}, {...}, {...}]`.
links = [{name = "Supplementary Material", url = "https://osf.io/9b8tv"}]

# Does this page contain LaTeX math? (true/false)
math = true

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
[image]
  # Caption (optional)
  caption = ""

  # Focal point (optional)
  # Options: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight
  focal_point = "BottomLeft"
    
# Almetric and Dimension badges
add_badge = true

+++

{{< metrics >}}
